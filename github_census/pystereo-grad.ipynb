{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from scipy.ndimage import filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "i = 0\n",
    "while True:\n",
    "    try:\n",
    "        l = np.load('l{0}.npy'.format(i)).astype(np.float)\n",
    "        gt = np.load('g{0}.npy'.format(i)).astype(np.float)\n",
    "        costs = np.load('b{0}.npy'.format(i)).astype(np.float)\n",
    "        acosts = np.load('a{0}.npy'.format(i)).astype(np.float)\n",
    "        box_costs = (filters.uniform_filter(costs,[7,7,1],mode='nearest')*(7*7)).astype(np.int)\n",
    "        best = np.argmin(box_costs,2)\n",
    "    except:\n",
    "        break\n",
    "    max_disp = int(costs.shape[-1])\n",
    "    image_width = costs.shape[1]\n",
    "    image_height = costs.shape[0]\n",
    "    data_size = costs.shape[0]*costs.shape[1]\n",
    "    mask = np.ones_like(gt)\n",
    "    mask[np.where(gt < 0)] = 0\n",
    "    print gt.shape\n",
    "    for y in xrange(image_height):\n",
    "        for x in xrange(1,image_width):\n",
    "            gp = gt[y,x-1]\n",
    "            gn = gt[y,x]\n",
    "\n",
    "            #if best[y,x] != int(round(gt[y,x])):\n",
    "            #    continue\n",
    "            #if gp == -2 or gp == -1 or gn == -2 or gn == -1:\n",
    "            #    continue\n",
    "            if gp == -2 or gn == -2:\n",
    "                continue\n",
    "            ft = [gn - gp,round(gn)-round(gp)]\n",
    "\n",
    "            for img in [l,costs,acosts]:\n",
    "                cp = img[y,x-1,:]\n",
    "                cn = img[y,x,:]\n",
    "                ft.append((cn - cp).sum())\n",
    "            data.append(ft)\n",
    "    for y in xrange(1,image_height):\n",
    "        for x in xrange(image_width):\n",
    "            gp = gt[y-1,x]\n",
    "            gn = gt[y,x]\n",
    "            \n",
    "            #if best[y,x] != int(round(gt[y,x])):\n",
    "            #    continue\n",
    "            #if gp == -2 or gp == -1 or gn == -2 or gn == -1:\n",
    "            #    continue\n",
    "            if gp == -2 or gn == -2:\n",
    "                continue\n",
    "            ft = [gn - gp,round(gn)-round(gp)]\n",
    "\n",
    "            for img in [l,costs,acosts]:\n",
    "                cp = img[y-1,x,:]\n",
    "                cn = img[y,x,:]\n",
    "                ft.append(((cn - cp)).sum())\n",
    "            data.append(ft)\n",
    "    i = i + 1\n",
    "    print len(data)\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print data.shape\n",
    "import pandas as pd\n",
    "data_f = pd.DataFrame(data)\n",
    "#data_f = data[]\n",
    "data_f[1] = (data_f[1] != 0.0).astype(np.int)\n",
    "data_f = data_f.drop(0,1) # drop real gt\n",
    "data_f = data_f.drop(4,1) # drop abs dif\n",
    "no_grad = np.array(data_f[data_f[1] == 0])[:,1:]\n",
    "grad = np.array(data_f[data_f[1] == 1])[:,1:]\n",
    "total = np.array(data_f)\n",
    "print no_grad.shape, grad.shape,total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hist2d(z,nbins=10):\n",
    "    \n",
    "    x = z[:,1]\n",
    "    y = z[:,2]\n",
    "    verification = z[:,0]\n",
    "    print x.max(),x.min()\n",
    "    print y.max(),y.min()\n",
    "    print verification.max(),verification.min()\n",
    "    _, xedges, yedges = np.histogram2d(x,y,bins=nbins)\n",
    "    avgarr = np.zeros((nbins, nbins))\n",
    "    H = np.zeros((nbins,nbins))\n",
    "    # determine the X and Y bins each sample coordinate belongs to\n",
    "    xbins = np.digitize(x, xedges[1:-1])\n",
    "    ybins = np.digitize(y, yedges[1:-1])\n",
    "\n",
    "    # calculate the bin sums (note, if you have very many samples, this is more\n",
    "    # effective by using 'bincount', but it requires some index arithmetics\n",
    "    for xb, yb, v in zip(xbins, ybins, verification):\n",
    "        avgarr[yb, xb] += v\n",
    "        H[yb,xb]+=1\n",
    "\n",
    "    # replace 0s in H by NaNs (remove divide-by-zero complaints)\n",
    "    # if you do not have any further use for H after plotting, the\n",
    "    # copy operation is unnecessary, and this will the also take care\n",
    "    # of the masking (NaNs are plotted transparent)\n",
    "    divisor = H.copy()\n",
    "    divisor[divisor==0.0] = np.nan\n",
    "\n",
    "    # calculate the average\n",
    "    avgarr /= divisor\n",
    "    return avgarr,xedges,yedges,H\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "%matplotlib inline\n",
    "grow =np.arange(grad.shape[0])\n",
    "nrow = np.arange(no_grad.shape[0])\n",
    "gidx = np.random.choice(grow,1000)\n",
    "nidx = np.random.choice(nrow,1000)\n",
    "plt.figure()\n",
    "if False:\n",
    "    plt.plot(abs(grad[gidx,0]),abs(grad[gidx,1]),ms=5,lw=0,marker='.')\n",
    "    plt.plot(abs(no_grad[nidx,0]),abs(no_grad[nidx,1]),ms=5,lw=0,marker='.')\n",
    "\n",
    "    plt.grid(True)\n",
    "if False:\n",
    "    plt.hexbin(abs(grad[:,0])+1,abs(grad[:,1])+1)\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.hexbin(abs(no_grad[:,0])+1,abs(no_grad[:,1])+1)\n",
    "if False:\n",
    "    res,xbins,ybins,H = hist2d(abs(total),20)\n",
    "    plt.imshow(res,origin='lower')\n",
    "    plt.xlabel('color')\n",
    "    plt.xticks(np.arange(20),np.unique(xbins))\n",
    "    plt.yticks(np.arange(20),np.unique(ybins))\n",
    "    plt.ylabel('sum disp diff')\n",
    "    plt.colorbar()\n",
    "    plt.figure()\n",
    "    plt.imshow(res > 0.5,origin='lower')\n",
    "    plt.figure()\n",
    "    plt.imshow(H,origin='lower',norm=LogNorm())\n",
    "    plt.colorbar()\n",
    "if True:\n",
    "    from collections import defaultdict\n",
    "    cntr = defaultdict(float)\n",
    "    prob = defaultdict(float)\n",
    "    xscale = 0.1\n",
    "    yscale = 0.001\n",
    "    for z,x,y in abs(total):\n",
    "        cntr[(int(x*xscale),int(y*yscale))] += z\n",
    "        prob[(int(x*xscale),int(y*yscale))] += 1\n",
    "    bad_keys = []\n",
    "    for key in cntr:\n",
    "        cntr[key] = cntr[key] / prob[key]\n",
    "        if prob[key] < 15:\n",
    "            bad_keys.append(key)\n",
    "    for key in bad_keys:\n",
    "        del cntr[key]\n",
    "    x = []\n",
    "    y = []\n",
    "    c = []\n",
    "    for key in cntr:\n",
    "        x.append(key[0])\n",
    "        y.append(key[1])\n",
    "        c.append(cntr[key])\n",
    "    plt.scatter(x,y,c=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.scatter(x,y,c=c,s=250)\n",
    "plt.title('Probability of being an edge (n < 10 discarded)')\n",
    "plt.ylabel('SAD between Census correlations divided by 100')\n",
    "plt.xlabel('color diff divided by 10')\n",
    "plt.grid(False)\n",
    "plt.xlim(0,max(x))\n",
    "plt.ylim(0,max(y))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "abs_x = abs(total[:,1:])\n",
    "abs_xy = (abs_x[:,0]*abs_x[:,1]).reshape([-1,1])\n",
    "X = np.hstack([abs_x,abs_xy])\n",
    "y = total[:,0].astype(np.int)\n",
    "model = RandomForestClassifier(n_jobs=-1,max_depth=4)#SGDClassifier(n_jobs=-1,loss='hinge',penalty='l2',fit_intercept=True,class_weight='balanced')\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.coef_,model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
